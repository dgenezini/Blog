[{"content":"Introduction Automated software tests are a requirement for ensuring we are delivering a product with quality to our users. It helps in finding bugs and requirements not fulfilled at development time, but also decreases the cost of maintenance by making the future changes to our code safer. Besides, the act of writing testable code alone increases the quality of the code we are writing because testable code has to be decoupled.\nIn this last post of this series, I\u0026rsquo;ll show how to analyze and enforce a minimum code coverage in our applications, and how to use integration tests to increase our testing surface.\nWhat is code coverage? Code coverage is a software metric that shows how much of our code is executed (covered) by our automated tests. It is shown as a percentage and can be calculated with different formulas, based on the number of lines or branches, for example. The higher the percentage, more of our code is being tested.\nAnalyzing the code coverage of our application In this example, we have an ASP.NET Core API with a simple use case class that checks an input number and returns a string telling if the number is even or odd:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 using CodeCoverageSample.Interfaces; namespace CodeCoverageSample.UseCases; public class IsEvenUseCase : IIsEvenUseCase { public string IsEven(int number) { if (number % 2 == 0) { return \u0026#34;Number is even\u0026#34;; } else { return \u0026#34;Number is odd\u0026#34;; } } } For now, we have only one unit test for this use case class:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 using CodeCoverageSample.UseCases; namespace CodeCoverageSample.UnitTests; public class IsEvenUseCaseTests { [Fact] public void EvenNumber_ReturnsEven() { //Arrange var isEvenUseCase = new IsEvenUseCase(); //Act var result = isEvenUseCase.IsEven(2); //Assert Assert.Equal(\u0026#34;Number is even\u0026#34;, result); } } To analyze the code coverage of our application, first we need to install Coverlet\u0026rsquo;s MSBuild integration using the coverlet.msbuild nuget package in our test project:\nInstall-Package coverlet.collector Then, run the dotnet test command with the Coverlet options on the solution or project folder:\ndotnet test -p:CollectCoverage=true -p:CoverletOutputFormat=opencover -p:CoverletOutput=../TestResults We are using the following options:\nCollectCoverage: Inform dotnet test to use coverlet to collect the code coverage data; CoverletOutputFormat: The format of the report that coverlet will generate (opencover, cobertura, json). More here; CoverletOutput: The path where the coverage report will be saved in. This path is relative to the test project; This will print the code coverage result in a table and generate a report file named TestResults.opencover.xml:\n‚ö†Ô∏è We can also run coverlet on the command line with the coverlet.collector nuget package, but it has limited options and doesn\u0026rsquo;t print the results in the command line. More details here;\nGenerating HTML reports Coverlet generates the report in formats that are not easily readable by humans, so we need to generate an HTML report based on Coverlet report. To do it, we\u0026rsquo;ll usa a tool called ReportGenerator.\nInstalling ReportGenerator ReportGenerator is installed as a .NET global tool.\nTo do this, we run the following command:\ndotnet tool install --global dotnet-reportgenerator-globaltool --version 4.8.6 Generating an HTML report of the opencover report To generate an HTML report based on a Coverlet report, we run the following command:\nreportgenerator \u0026#34;-reports:TestResults.opencover.xml\u0026#34; \u0026#34;-targetdir:coveragereport\u0026#34; -reporttypes:Html We are using the following options:\nreports: The path to the coverage report; targetdir: The path where the HTML report will be saved in; reporttypes: The format the report will be generated in. The command output will tell the relative path to the generated report: coveragereport\\index.html.\nOpening the coveragereport\\index.html file we can see the project Line and Branch coverage:\nClicking on CodeCoverageSample.UseCases.IsEvenUseCase we can see details of the code coverage by method (in the table) and the line and branch coverage for the class:\nLine vs Branch coverage But what is line coverage and branch coverage?\nLine coverage: Indicates the percentage of lines that are covered by the tests; Branch coverage: Indicates the percentage of logical paths that are covered by the tests (if, else, switch condition, etc). In the example below, we can see that two lines in the else branch are not covered by the tests.\nThis will result in:\n50% of branch coverage, because only the if branch is covered; 71.4% of line coverage, because only 5 of the 7 lines are covered. Code coverage on Visual Studio The is an extension called Run Coverlet Report that integrates Coverlet and ReportGenerator with Visual Studio.\nFirst, we need to install the coverlet.collector nuget package in our test projects. Xunit template already has this package installed by default. Install-Package coverlet.collector Then, navigate to Extensions \u0026gt; Manage extensions and install the Run Coverlet Report extension. Navigate to the new option Tools \u0026gt; Run Code Coverage. This will generate the ReportGenerator HTML report that will be open in Visual Studio. Also, after running the code coverage tool, Visual studio will read the coverlet report and show the coverage in our source file:\nImproving our code coverage Fixing the unit tests Now we will implement the OddNumber_ReturnsOdd method to test the logical path we didn\u0026rsquo;t test before:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 using CodeCoverageSample.UseCases; namespace CodeCoverageSample.UnitTests; public class IsEvenUseCaseTests { [Fact] public void EvenNumber_ReturnsEven() { //Arrange var isEvenUseCase = new IsEvenUseCase(); //Act var result = isEvenUseCase.IsEven(2); //Assert Assert.Equal(\u0026#34;Number is even\u0026#34;, result); } [Fact] public void OddNumber_ReturnsOdd() { //Arrange var isEvenUseCase = new IsEvenUseCase(); //Act var result = isEvenUseCase.IsEven(3); //Assert Assert.Equal(\u0026#34;Number is odd\u0026#34;, result); } } This will increase our average coverage to 50% of branch and 22.58% of line:\nAnd 100% for the IsEvenUseCase class:\nImplementing integration tests Integration tests using the WebApplicationFactory class (More here) are also considered in the code coverage reports. Let\u0026rsquo;s look at our IsEvenController and Program classes coverage:\nLet\u0026rsquo;s implement a simple integration test. It will just instantiate our API and make a call passing a number and validate the results:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 using Microsoft.AspNetCore.Mvc.Testing; using System.Net; namespace CodeCoverageSample.UnitTests.IntegrationTests; public class IsEvenIntegrationTest : IClassFixture\u0026lt;WebApplicationFactory\u0026lt;Program\u0026gt;\u0026gt; { private readonly WebApplicationFactory\u0026lt;Program\u0026gt; _factory; public IsEvenIntegrationTest(WebApplicationFactory\u0026lt;Program\u0026gt; factory) { _factory = factory; } [Theory] [InlineData(2, \u0026#34;Number is even\u0026#34;)] [InlineData(3, \u0026#34;Number is odd\u0026#34;)] public async Task Number_ReturnsCorrectAndOk(int number, string expectedResult) { var HttpClient = _factory .CreateClient(); //Act var HttpResponse = await HttpClient.GetAsync($\u0026#34;/iseven/{number}\u0026#34;); //Assert Assert.Equal(HttpStatusCode.OK, HttpResponse.StatusCode); var ResponseStr = await HttpResponse.Content.ReadAsStringAsync(); Assert.Equal(expectedResult, ResponseStr); } } Now we run the code coverage report again and the IsEvenController and Program classes are covered by the tests:\nRemoving code from the code coverage analysis If we want to remove a class or method from the code coverage analysis, we can decorate it with the ExcludeFromCodeCoverage attribute:\n1 2 3 4 5 6 7 8 9 using System.Diagnostics.CodeAnalysis; namespace CodeCoverageSample; [ExcludeFromCodeCoverage] public class DoNotTestMe { ... } ‚ÑπÔ∏è We can also create custom attributes to exclude from coverlet code coverage. Details here.\nIgnoring auto-properties Coverlet has the SkipAutoProps option to exclude the auto-properties from the coverage report.\nFor example, this class doesn\u0026rsquo;t have any logic and doesn\u0026rsquo;t need that the get and set methods of its properties be tested:\n1 2 3 4 5 6 7 namespace CodeCoverageSample; public class NoLogicHere { public int Id { get; set; } public int Name { get; set; } } Just set the SkipAutoProps to true when running the code coverage from the command line:\ndotnet test -p:CollectCoverage=true -p:CoverletOutputFormat=opencover -p:CoverletOutput=TestResults -p:SkipAutoProps=true ‚ö†Ô∏è Unfortunately, the Run Coverage Report extension still doesn\u0026rsquo;t allow us to configure the coverlet parameters. There is an open pull request with this feature awaiting for approval here.\nEnforcing a minimum code coverage on the build pipeline Just like code style and code quality rules, that I talked about in my previous post, we need to enforce a minimum code coverage in our build pipeline to maintain a level of quality in our code. Coverlet has the Threshold option that we can set to a minimum percentage and it will fail the tests if our code coverage is below this percentage:\ndotnet test -p:CollectCoverage=true -p:CoverletOutputFormat=opencover -p:CoverletOutput=TestResults -p:SkipAutoProps=true -p:Threshold=80 We can also use the ThresholdType option to set the type of coverage to enforce. Not specifying will enforce all types of coverage (Line, Branch and Method). Details here.\nReferences and Links https://github.com/coverlet-coverage/coverlet https://github.com/coverlet-coverage/coverlet/blob/master/Documentation/MSBuildIntegration.md https://github.com/coverlet-coverage/coverlet/blob/master/Documentation/VSTestIntegration.md https://github.com/danielpalme/ReportGenerator https://marketplace.visualstudio.com/items?itemName=ChrisDexter.RunCoverletReport https://github.com/the-dext/RunCoverletReport/blob/master/README.md ","date":"2022-11-03T08:10:00-03:00","image":"https://blog.genezini.com/p/analyzing-and-enforcing-.net-code-coverage-with-coverlet/cover.png","permalink":"https://blog.genezini.com/p/analyzing-and-enforcing-.net-code-coverage-with-coverlet/","title":"Analyzing and enforcing .NET code coverage with coverlet"},{"content":"Introduction Static code analysis is a great tool for spotting some kinds of error in your code, for example, not disposing of objects that implement IDisposable. Also, it helps to enforce and validate if the code written is following a defined standard, for example, using PascalCase for class names and camelCase for parameter names.\nIn this post I\u0026rsquo;ll show how to use Roslyn Analyzers with C# to enforce some standards of code quality and code style on your code, throwing errors at compile time if any rules are not being respected and not allowing the code to be pushed to protected branches of the repository.\nRoslyn Analyzers Roslyn is the compiler platform for .NET. Roslyn Analyzers are static code analysis tools for Roslyn. They inspect your code for style, quality, maintainability, and practices that are likely to cause bugs. They work based on predefined rules that can have their severity configured in the EditorConfig file.\n.NET 5 and later have the analyzers enabled by default. To enable them in earlier versions of .NET, you can set the property EnableNETAnalyzers to true on project files that uses a project SDK or install them as a nuget package:\nSetting EnableNETAnalyzers on the project file 1 2 3 \u0026lt;PropertyGroup\u0026gt; \u0026lt;EnableNETAnalyzers\u0026gt;true\u0026lt;/EnableNETAnalyzers\u0026gt; \u0026lt;/PropertyGroup\u0026gt; Installing as a nuget package 1 Install-Package Microsoft.CodeAnalysis.NetAnalyzers Enabling more analyzers By default, only some rules are enabled, but we can configure this with the AnalysisMode property in the project file:\n1 2 3 \u0026lt;PropertyGroup\u0026gt; \u0026lt;AnalysisMode\u0026gt;Recommended\u0026lt;/AnalysisMode\u0026gt; \u0026lt;/PropertyGroup\u0026gt; The AnalysisMode property values allowed are different for .NET 6 and .NET 5 SDKs. Details here.\nHow to enable .NET Analyzers in VS Code .NET Analyzers work by default in Visual Studio, but they have to be enabled in VS Code.\n1 - Navigate to File \u0026gt; Preferences \u0026gt; Settings.\n2 - Navigate to Extensions \u0026gt; C# configuration or search for omnisharp.enableRoslynAnalyzers.\n3 - Check the Omnisharp: Enable Roslyn Analyzers option.\n4 - Navigate to Extensions \u0026gt; C# configuration or search for omnisharp.enableEditorConfigSupport.\n5 - Check the Omnisharp: Enable Editor Config Support option.\n6 - Restart C#/Omnisharp extension or VS Code.\nTypes of rules .NET Analyzers have many categories of rules, but here I\u0026rsquo;ll list just a few to explain how they interact with Visual Studio\u0026rsquo;s features.\nStandard formatting: Default Editorconfig options, like indent size and tabs or spaces;\nCode Style - .NET Formatting: Language specific indentation, whitespaces, and wrapping. For instance, use spaces before parentheses in method definitions.\nCode Style - .NET Language: C# and Visual Basic specific rules. Examples: using var instead of an explicit type, prefer auto properties instead of backing fields.\nCode Style - Naming Conventions: Rules about the naming of code elements, like enforcing PascalCase for classes\u0026rsquo; names and Async at the end of async methods\u0026rsquo; names.\nCode Style - Unnecessary code: Rules for code that is unreachable or unused variables, fields, etc.\nCode Quality: Rules to improve code quality. These rules help identify code that are likely to cause bugs or security problems. Examples: Do not declare static members on generic types, and Enums should have zero value.\nThe table below shows in which features of Visual Studio the fixes for these types of rules are applied on.\nFixes applied on üñπ Format üßπ Code Cleanup üí° Code Fix Standard Formatting ‚úîÔ∏è ‚úîÔ∏è ‚úîÔ∏è .NET Formatting ‚úîÔ∏è ‚úîÔ∏è ‚úîÔ∏è .NET Language ‚úîÔ∏è ‚úîÔ∏è Naming Conventions ‚úîÔ∏è Unnecessary Code ‚ùó ‚úîÔ∏è Code Quality ‚ùó ‚ùó Only some rules have fixes applied.\nEnforcing rules in our code Rules are configured in the EditorConfig file (that I explained in a Part 1 of this series) and their severity can be defined in three levels. Conflicts in the rules are resolved in the following order:\nSpecific rules Category rules All analyzers rules In the example below, Naming rules violations (IDE1006) will be considered Warning, because it is defined for the specific rule:\n1 2 3 4 5 6 # Defines that all analyzers rules are suggestions dotnet_analyzer_diagnostic.severity = suggestion # Defines that all Code Style analyzers rules are errors dotnet_analyzer_diagnostic.category-Style.severity = error # Defines that the rule IDE1006 is a warning dotnet_diagnostic.IDE1006.severity = warning 1. Generate an EditorConfig file from Visual Studio First, we need to create an EditorConfig file with the configuration of the rules we will use as standards.\nVisual Studio has a tool to help you configure the code style rules of your EditorConfig file, showing a snippet of code of how the rules work.\nGo to Tools \u0026gt; Options \u0026gt; Text Editor \u0026gt; C# \u0026gt; Code Style; Configure your Code Style preferences in the General, Formatting and Naming sub-menus. ‚ö†Ô∏è Don\u0026rsquo;t bother setting the severities here; some of them are only respected by Visual Studio and are not enforced on build and other IDEs; Back in the General sub-menu, click Generate .editoconfig file from settings and save it in the folder your solution file is in (.sln). ‚ö†Ô∏è If you are not using Visual Studio, you can use a sample and change it to your preferences, like the one from Roslyn.\n2. Configure all projects to use the recommended .NET Analyzers Next, we set the AnalysisMode property in all our project files.\nFor .NET 6 SDK and later, set it to Recommended or All.\n1 2 3 \u0026lt;PropertyGroup\u0026gt; \u0026lt;AnalysisMode\u0026gt;Recommended\u0026lt;/AnalysisMode\u0026gt; \u0026lt;/PropertyGroup\u0026gt; 3. Set severity Error for all analyzers rules In our EditorConfig, include this line to set severity to error for all rules.\n1 2 # Set severity = error for all analyzers dotnet_analyzer_diagnostic.severity = error 4. Correct the errors and override the severity for rules you don\u0026rsquo;t want to use If you are enabling the analyzers in an existing project, many errors will be shown. Correct them and override their severity if they don\u0026rsquo;t apply for you or you won\u0026rsquo;t correct them at the moment.\nSetting rules severity directly in EditorConfig file 1 2 3 4 5 6 7 # Other rules ... # Set severity = none to the rules that are not important for me dotnet_diagnostic.IDE0075.severity = none # Set severity = warning to the rules that need to be resolved later dotnet_diagnostic.IDE0047.severity = warning Setting rules severity from Visual Studio\u0026rsquo;s Error List For errors showing up in the Error List, you can right click on the rule and click on Set severity \u0026gt; Choose a severity. The severity configuration will be added to the EditorConfig file.\nSetting rules severity from Visual Studio\u0026rsquo;s Solution Explorer From Solution Explorer, open the Dependencies \u0026gt; Analyzers node below your project, then right click on the rule and click on Set severity \u0026gt; Choose a severity. The severity configuration will be added to the EditorConfig file.\n5. Enforce the rules on build Enabling the analyzers only shows the messages in our IDE. To really enforce those rules, we have to inform the compiler to fail in case of rules violations, blocking changes that are not compliant to the standard to be merged into protected branches of the repository.\nTo do this, we need to enable the property EnforceCodeStyleInBuild in all our project files.\n1 2 3 \u0026lt;PropertyGroup\u0026gt; \u0026lt;EnforceCodeStyleInBuild\u0026gt;true\u0026lt;/EnforceCodeStyleInBuild\u0026gt; \u0026lt;/PropertyGroup\u0026gt; Examples of rules being enforced Rules being enforced on Visual Studio Rules being enforced on VS Code Rules being enforced on dotnet build command Creating additional naming conventions Here are some naming conventions of the C# language:\nSymbols Convention Example class/record/struct PascalCase PhysicalAddress interface \u0026ldquo;I\u0026rdquo;+PascalCase IWorkerQueue public members PascalCase StartEventProcessing private/internal fields \u0026ldquo;_\u0026quot;+camelCase _workerQueue static fields \u0026ldquo;s_\u0026quot;+camelCase s_workerQueue local variables *Ô∏è camelCase isValid parameters camelCase name async methods PascalCase+\u0026ldquo;Async\u0026rdquo; GetStringAsync More details here.\nBy default, Visual Studio doesn\u0026rsquo;t create naming conventions for static fields, local variables, parameters and async methods. If we want to use them, we have to manually set those rules, as shown below.\n*Ô∏è Not specified in the docs, but Roslyn uses this convention.\nCreating the naming convention for async methods 1 2 3 4 5 6 7 8 9 10 dotnet_naming_rule.async_methods_should_be_pascalcase_async.severity = error dotnet_naming_rule.async_methods_should_be_pascalcase_async.symbols = async_methods dotnet_naming_rule.async_methods_should_be_pascalcase_async.style = pascalcase_async dotnet_naming_symbols.async_methods.applicable_kinds = method dotnet_naming_symbols.async_methods.applicable_accessibilities = * dotnet_naming_symbols.async_methods.required_modifiers = async dotnet_naming_style.pascalcase_async.required_suffix = Async dotnet_naming_style.pascalcase_async.capitalization = pascal_case Creating the naming convention for local variables and parameters 1 2 3 4 5 6 7 dotnet_naming_rule.locals_and_parameters_should_be_pascal_case.severity = error dotnet_naming_rule.locals_and_parameters_should_be_pascal_case.symbols = locals_and_parameters dotnet_naming_rule.locals_and_parameters_should_be_pascal_case.style = camel_case dotnet_naming_symbols.locals_and_parameters.applicable_kinds = parameter, local dotnet_naming_style.camel_case.capitalization = camel_case How to ignore the CA1707 rule (Identifiers should not contain underscores) on test projects Some conventions for naming test methods use underscore. If that is your case, you will receive a violation for the CA1707 rule. To disable the rule only on the test project, create a file named GlobalSuppressions.cs in the root of your test project with the content below.\n1 2 3 using System.Diagnostics.CodeAnalysis; [assembly: SuppressMessage(\u0026#34;Naming\u0026#34;, \u0026#34;CA1707:Identifiers should not contain underscores\u0026#34;, Justification = \u0026#34;Not applicable for test names\u0026#34;, Scope = \u0026#34;module\u0026#34;)] Third-party analyzers There are third-party analyzers that can have additional rules that can be useful. These are some:\nRoslynator StyleCop Sonar Analyzer References and Links https://learn.microsoft.com/en-us/visualstudio/code-quality/install-net-analyzers?view=vs-2022 https://www.jetbrains.com/help/rider/Using_EditorConfig.html#export-code-style-settings https://marketplace.visualstudio.com/items?itemName=MadsKristensen.EditorConfig ","date":"2022-10-25T08:00:00-03:00","image":"https://blog.genezini.com/p/enforcing-.net-code-style-rules-at-compile-time/cover.png","permalink":"https://blog.genezini.com/p/enforcing-.net-code-style-rules-at-compile-time/","title":"Enforcing .NET code style rules at compile time"},{"content":"Introduction When working with other people and multiple editors/IDEs, it is common to have different editor settings, losing consistency in formatting styles of the code. For example:\nUsing tabs/spaces and different sizes of indentation, making your code harder to read; Using different encoding between files, causing hard to find bugs at runtime (showing invalid characters) and breaking automated tests. In this post I\u0026rsquo;ll show how to maintain a standard for everyone who works in the code, no matter the editor used, and in a next post I\u0026rsquo;ll show how to enforce these (and other) rules on build and in the continuous integration pipeline.\nEnter the EditorConfig file The EditorConfig file is used by editors and IDEs to define editor preferences for the project. Without it, IDEs and editors will use their general configuration, causing divergences in the files edited on them.\nMany editors and IDEs support the EditorConfig file by default, and others have plugins to support it. Here are some:\nVisual Studio (Built-in); JetBrains Rider (Built-in); GitHub (Built-in); VS Code (Plugin); Vim (Plugin); Emacs (Plugin); Sublime (Plugin); It has a default name of .editorconfig and is an INI file where sections are filename filters, for instance:\n[*.cs] for .cs files; [scripts/**.js] for javascript files inside the scripts folder and subdirectories; [{package.json}] for the package.json file only. More details here\nThe EditorConfig can be put in any directory and be overridden by EditorConfig files in child directories, but for better visibility, they should be in the same directory as the .NET solution file.\nAdding an EditorConfig to your project To include an EditorConfig to your project, just create a file named .editorconfig in the same directory of your solution file (.sln) with the content below.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # Top-most EditorConfig file. root = true # Section for C# files # All rules below apply only to .cs files [*.cs] #### Core EditorConfig Options #### # Indentation and spacing indent_style = space indent_size = 4 # New line preferences end_of_line = crlf insert_final_newline = false trim_trailing_whitespace = true # Charset preference charset = utf-8 This file set these rules:\nroot: No editorconfig file in parent directories will be read; indent_style: Indentation should use space; indent_size: Indentation should use 4 space characters; end_of_line: Lines should end with CR+LF characters; insert_final_newline: Do not automatically insert empty lines at the end of the files; trim_trailing_whitespace: Empty lines should have no space characters; charset: Files should be encoded with UTF-8 format. More details here.\n‚ö†Ô∏è GIT can change the line ends to LF on pushes to the repository and change it back to CRLF on checkouts. Then, the end_of_line settings can be safely set to CRLF. GIT for Windows suggests this configuration by default at installation. Details on how to configure are here.\n‚ö†Ô∏è UTF-8 with BOM is not required nor recommended, according to the Unicode standard. More here.\n‚ÑπÔ∏è In .NET, the EditorConfig file can also be used to define analyzers rules and severities specific to the .NET environment. In a next post, I\u0026rsquo;ll show how to configure these rules.\nAppling the new formatting rules to code When we change the formatting rules for an existing project, the changes are not applied automatically. We need to manually trigger an auto-format.\nVisual Studio First, we have to include the Format document fixer to a Code Cleanup profile.\n1 - Navigate to Analyze \u0026gt; Code Cleanup \u0026gt; Configure Code Cleanup.\n2 - Include the Format document fixer for the profile you wish to run on save.\n3 - On the menu, select Analyze \u0026gt; Code Cleanup \u0026gt; Run Code Cleanup (Yout Profile) on Solution.\n‚ö†Ô∏è Visual Studio\u0026rsquo;s format document doesn\u0026rsquo;t change the file encoding. You have to use the dotnet-format or another tool for that.\nVS Code VS Code doesn\u0026rsquo;t have a feature to format all files at once. You have to use the Format Files extension.\n1 - Install the Format Files extension.\n2 - Navigate to View \u0026gt; Command Palette or press Ctrl+Shift+P.\n3 - Select the Start Format Files: Workspace or Start Format Files: From Glob option.\nJetBrains Rider Select Code \u0026gt; Reformat Code or press Ctrl+Alt+Enter.\nFormat on save When we create an EditorConfig file, the supported editors will also use the configurations for their auto-format features.\nHere I show how to enable the auto-format on file save in some editors.\nFormat on save in Visual Studio Visual Studio 2022 doesn\u0026rsquo;t have a format on save feature, but it can run a Code Cleanup on save. This way we can configure a Code Cleanup profile to run a Format document and use it on save.\n‚ÑπÔ∏è For Visual Studio 2019, there is an extension that enables the same feature.\n1 - Configure your Code Cleanup profile to run the Format document fixer, as shown in the previous section of this post.\n2 - Navigate to Tools \u0026gt; Options \u0026gt; Text Editor \u0026gt; Code Cleanup.\n3 - Check the Run Code Cleanup profile on Save option and select the Code Cleanup profile to run on save.\nNow Visual Studio will format your files on every save.\nFormat on save in VS Code 1 - Navigate to File \u0026gt; Preferences \u0026gt; Settings.\n2 - Navigate to Text Editor \u0026gt; Formatting or search for editor.formatOnSave.\n3 - Check the Editor: Format On Save option.\nFormat on save in JetBrains Rider 1 - Navigate to File \u0026gt; Settings \u0026gt; Tools \u0026gt; Actions on Save.\n2 - Check the Reformat and Cleanup Code option.\n3 - Select the Reformat Code profile.\nReferences and Links https://editorconfig.org/ https://devblogs.microsoft.com/visualstudio/bringing-code-cleanup-on-save-to-visual-studio-2022-17-1-preview-2/ https://learn.microsoft.com/en-us/visualstudio/ide/create-portable-custom-editor-options?view=vs-2022 https://learn.microsoft.com/en-us/dotnet/core/tools/dotnet-format ","date":"2022-10-18T08:00:00-03:00","image":"https://blog.genezini.com/p/defining-formatting-rules-in-.net-with-editorconfig/cover.png","permalink":"https://blog.genezini.com/p/defining-formatting-rules-in-.net-with-editorconfig/","title":"Defining formatting rules in .NET with EditorConfig"},{"content":"Introduction Visual Studio Code is the most used IDE according to the Stack Overflow 2022\u0026rsquo;s Developer Survey and it has lots of extensions to help us be more productive. Even developers who use another main IDE probably use VS Code for some part of their jobs.\nIn this post I\u0026rsquo;ll show some of the extensions that I use to work, study and write this blog.\n1 - Project Manager Project Manager creates an icon in the side bar and lets you save opened folders for quick access. This way you don\u0026rsquo;t have to look for the project folder every time you open it; just open VS Code and select it from the menu.\nI use it in combination with the Git Worktree extension that I talked about in my other post. I save my long lived branches (for example, the main branch) as a project and then I can switch to other worktrees from there.\nIt also allows you to tag the projects for better organization, so I tag the different components of a solution with the project name.\nDownload\n2 - Compare Folders Compare Folders shows the difference between two folders\u0026rsquo; content and displays an editable comparison of the files side by side. It also allows you to copy the files present on only one side to the other.\nI use it mostly to compare two branches or two versions of a repository.\nDownload\n3 - Path Intellisense Path Intellisense shows an intellisense menu for choosing a file name. It works with HTML, CSS, Typescript, Javascript and other types of files.\nDownload\n4 - Draw.io Integration Draw.io is a free and open source drawing software that can be used to create diagrams, wireframes, etc.\nThis extension allows you to open and edit your .drawio files inside VS Code.\nDownload\n5 - Excalidraw Excalidraw is a whiteboard tool that lets you sketch diagrams that have a hand-drawn feel to them. Just like the Draw.io Integration, this extension allows you to open and edit .excalidraw files inside VS Code.\nDownload\n6 - Docker for Visual Studio Code This extension by Microsoft lets you manage docker images, containers, networks and volumes. It is a great alternative for the Docker Desktop Dashboard, that is now paid for commercial use.\nIt is really useful for attaching to a running container\u0026rsquo;s shell or looking into its logs with just one click. It also lets you open and edit files inside the container.\nDownload\n7 - vs-openapi-designer This extension renders the OpenAPI YAML/JSON document in a side panel for preview. It helps a lot in validating the complex API contracts that have lots of files.\nDownload\n8 - Terraform Terraform extension adds syntax support for .tf file, with snippets and intellisense.\nDownload\n9 - VSCode Great Icons A really well done pack of icons for VS Code. I like it because it has just two variations for the folders, keeping it cleaner than other icons packs, who end up leaving the files explorer confusing.\nDownload\n10 - Color Highlight Color Highlight shows the preview for colors in your CSS and HTML files.\nDownload\n11 - Import Cost This extension displays inline information of the size of the imported package. It uses webpack to detect the package size and works with import and require().\nDownload\n","date":"2022-10-11T07:00:00-03:00","image":"https://blog.genezini.com/p/vs-code-extensions-worth-trying-out/cover.png","permalink":"https://blog.genezini.com/p/vs-code-extensions-worth-trying-out/","title":"VS Code extensions worth trying out"},{"content":"Introduction When working on a project, many times we have to switch to a different branch to help a colleague, fix a bug, or to work on another feature (because of a change in priorities or blocks).\nIn these situations, we have some options:\nClone again to another folder: This was the option that I used up until some time ago, but if you are working on a big code base, it may take some time to download the remote repository and it will use more space in the disk because you will end up with one copy of the repository for each branch;\nStash or commit changes and checkout the other branch: This is ok, but it takes more steps and doesn\u0026rsquo;t allow for multiple branches checked out in parallel;\nAdd a new working tree: This is what I prefer to do because I can have only one local repository shared between the branches.\nIn this post, I\u0026rsquo;ll show how to use git working trees to make those branch switches easier.\nBasics of how a GIT repository works When we use the git clone command, GIT creates two things in the destination: a working tree and a copy of the remote repository (in a .git folder inside the working tree directory).\n‚ÑπÔ∏è git clone --bare clones only the repository in the root folder, without the working tree.\nRepository The GIT repository is a structured directory where GIT stores its objects, branches, and other components used to control the versions of our files.\nWorking tree The working tree is where the actual files we work on are stored. When we use git checkout, GIT changes all the files in the working tree to reflect the branch we are working on.\nExample 1 git clone https://github.com/dgenezini/MyProject.git MyProject Within the repository, there are a lot of files and folders, but, for the scope of this post, these are the most important ones:\nobjects = Directory storing blobs (files), trees (directories), and commits; refs = Directory storing pointers to the commits that are the heads of each branch or tag in the repository; HEAD = File pointing to the branch or tag that is checked in in the working tree; index = File used to control what is staged. Why use GIT Worktree? Using the git worktree command, we can create multiple working trees pointing to the same local repository, sharing most of the repository between them.\nInstead of a .git directory, the additional working trees have a .git file with a pointer to a working tree folder inside the local repository.\nIn the working tree folder, we have the GIT components that are not shared with the other working trees. Note that most of the repository, including the objects folder (files, directories and commits), is shared.\nThese are the main components in the working tree folders:\nHEAD = File pointing to the branch that is checked out in the working tree; index = File used to control what is staged in the working tree; commondir = File pointing to the local GIT repository. Using GIT Worktree I like to have all the working trees as subfolders, so I start by creating a folder with the name of the repository and cloning the default branch to a folder with the name of the branch (in my case, main).\n1 2 mkdir MyProject \u0026amp;\u0026amp; cd MyProject git clone https://github.com/dgenezini/MyProject.git main This is the result I want:\n1 2 3 4 MyProject/ \u0026lt;-- My repo name ‚îî‚îÄ‚îÄ main \u0026lt;-- Branch name ‚îú‚îÄ‚îÄ .git \u0026lt;-- Local repository ‚îî‚îÄ‚îÄ README.md ‚ÑπÔ∏è Some people use git clone --bare to pull the repository without a working tree, but the --bare option does not map the branches to their remote origins, so I prefer to clone my default branch (in this example, the main branch), because it is a long living branch, that way I don\u0026rsquo;t have to manually map the remote origins for every working tree created.\nAdding a working tree Inside the main directory, use the git worktree add command:\n1 git worktree add [path] [branch] Example:\n1 2 cd main git worktree add ../featureA featureA This is will be the result:\n1 2 3 4 5 6 7 MyProject/ \u0026lt;-- My repo name ‚îú‚îÄ‚îÄ featureA \u0026lt;-- Branch name ‚îÇ¬†‚îú‚îÄ‚îÄ .git \u0026lt;-- File pointing to ../main/.git ‚îÇ¬†‚îî‚îÄ‚îÄ README.md ‚îî‚îÄ‚îÄ main \u0026lt;-- Branch name ‚îú‚îÄ‚îÄ .git \u0026lt;-- Git local repository ‚îî‚îÄ‚îÄ README.md ‚ÑπÔ∏è You can use the git worktree add and other git commands inside any working tree directory.\n‚ö†Ô∏è If you are using windows, change the slash on the path from ../featureA to ..\\featureA.\nChanging to a working tree Just change the directory you are working on:\n1 cd ../featureA Removing a working tree Inside the main directory, use the git worktree remove command:\n1 git worktree remove [branch] Example:\n1 git worktree remove featureA or just delete the working tree folder (featureA in this example), then use git worktree prune to clean the invalid working trees.\nGit Worktrees extension for Visual Studio Code Git Worktrees is a free extension for Visual Studio Code that helps us work with git working trees.\nAdding a working tree Open the Command Palette (Ctrl+Shift+P) and type worktree add\nChanging to a working tree Open the Command Palette (Ctrl+Shift+P), search for worktree list and select Git Worktree: List.\nSelect the branch you want to work on and VS Code will open another window in that working tree.\nRemoving a working tree Open the Command Palette (Ctrl+Shift+P), search for worktree remove and select Git Worktree: Remove.\nSelect the branch you want to remove.\n‚ö†Ô∏è You can\u0026rsquo;t remove the working tree you have currently open in VS Code.\nChanging the working tree from Visual Studio 2022 Visual Studio is my favorite IDE for working with .NET, so it is important that I can change easily between working trees from within it.\nOnce you open the project from the working tree for the first time, Visual Studio will keep track of the working tree as a repository in the status bar. Just change it from there and it will load the project.\nReferences e links https://marketplace.visualstudio.com/items?itemName=eamodio.gitlens https://marketplace.visualstudio.com/items?itemName=GitWorktrees.git-worktrees ","date":"2022-09-30T09:35:00-03:00","image":"https://blog.genezini.com/p/working-on-multiple-git-branches-in-parallel/cover.png","permalink":"https://blog.genezini.com/p/working-on-multiple-git-branches-in-parallel/","title":"Working on multiple GIT branches in parallel"},{"content":"Introduction Although there are many definitions about the scope of an integration test, Martin Fowler defines Narrow integration tests, where the integration with other systems are tested using mocks, and Broad integration tests, where they communicate using real APIs.\nIn this post, I\u0026rsquo;ll explain how to create mocks for HTTP APIs in narrow integration tests using the WireMock.Net library.\nWhat should we mock? Vladimir Khorikov has a concept of managed dependencies and unmanaged dependencies, which I consider complementary to Martin Fowler\u0026rsquo;s, to choose what should be to mocked.\nManaged dependencies are external systems controlled by us and accessed only by our application (for example, a database). On the other side, unmanaged dependencies are external systems not controlled by us or also accessed by other applications (like a third party API or a message broker).\nVladimir says that we should test our system against managed dependencies, while mocking unmanaged dependencies. I believe this definition is more like a guideline than a rule. For example, in a scenario where our application posts in a message broker for other system to read, that is, the message broker is an unmanaged dependency, we could test the integration with the message broker to validate that the message is being written in the right format (according to contract). This can have value if we want to test if updates to the library used to communicate with the message broker didn\u0026rsquo;t introduce breaking changes in the message.\nWhy use mocks? The reason we use integration tests is to test our components (or classes), which are tested independently in unit tests, working in communication with each other. When we interact with an API, we follow a protocol and trust a contract of communication, that is, that the API will accept parameters X as input and will return an response Y.\nThat way, the inner works of that external API is not in the scope of our integration tests.\nThis doesn\u0026rsquo;t remove the requirement of functional tests; it only reduces the amount of those tests, which are more expensive to execute.\nReducing the integration tests only to our application, we have some benefits:\nSpeed of the tests, because we remove the network latency; No need of data in external systems to execute the tests; Reduced brittleness of the tests, that could break in case of the external API instability or external data that changed; More trust in the test results. Using WireMock.Net In this example, I\u0026rsquo;ve built an API that consumes the Pok√©API service to look for a Pok√©mon data and return it to the client.\nController The controller is simple and use the Refit library to abstract the Pok√©API call and then, returns the data.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 using Microsoft.AspNetCore.Mvc; using Refit; namespace PokemonInfoAPI.Controllers { [ApiController] [Route(\u0026#34;[controller]\u0026#34;)] public class PokemonInfoController : ControllerBase { private readonly IConfiguration _configuration; public PokemonInfoController(IConfiguration configuration) { _configuration = configuration; } [HttpGet(\u0026#34;{pokemonName}\u0026#34;)] public async Task\u0026lt;ActionResult\u0026lt;PokemonInfo\u0026gt;\u0026gt; GetAsync(string pokemonName) { try { var pokeApi = RestService.For\u0026lt;IPokeApi\u0026gt;(_configuration[\u0026#34;PokeApiBaseUrl\u0026#34;]); return Ok(await pokeApi.GetPokemonInfo(pokemonName)); } catch (ApiException ex) { if (ex.StatusCode == System.Net.HttpStatusCode.NotFound) { return NotFound(); } return StatusCode(500); } } } } Default integration test We start with a default integration test, using ASP.NET Core\u0026rsquo;s WebApplicationFactory class. The test creates an instance of our application e makes a request to the /pokemoninfo endpoint with the parameter charmander. Out application calls the Pok√©API.\n‚ö†Ô∏è If you\u0026rsquo;re using the Startup.cs class in your application, instanciate WebApplicationFactory\u0026lt;Startup\u0026gt; instead of WebApplicationFactory\u0026lt;Program\u0026gt;.\n‚ö†Ô∏è If you\u0026rsquo;re not using the Startup.cs class, it\u0026rsquo;s not possible to use top-level statements in your application to use the WebApplicationFactory in your tests.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 using FluentAssertions; using Microsoft.AspNetCore.Mvc.Testing; using System.Net; using System.Text.Json; namespace PokemonInfoAPI.IntegrationTests { public class PokemonInfoTests: IClassFixture\u0026lt;WebApplicationFactory\u0026lt;Program\u0026gt;\u0026gt; { private readonly WebApplicationFactory\u0026lt;Program\u0026gt; _factory; public PokemonInfoTests(WebApplicationFactory\u0026lt;Program\u0026gt; factory) { _factory = factory; } [Fact] public async Task Get_Existing_Pokemon_Returns_200() { //Arrange var HttpClient = Factory.CreateClient(); //Act var HttpResponse = await HttpClient.GetAsync(\u0026#34;/pokemoninfo/charmander\u0026#34;); //Assert HttpResponse.StatusCode.Should().Be(HttpStatusCode.OK); var ResponseJson = await HttpResponse.Content.ReadAsStringAsync(); var PokemonInfo = JsonSerializer.Deserialize\u0026lt;PokemonInfo\u0026gt;(ResponseJson); PokemonInfo.Should().BeEquivalentTo(ResponseObj); } } } Setting up a mock for Pok√©API WireMock.Net is a library that let you create mocks for HTTP APIs. It creates a web server in the same process of our test and exposes an URL to be used by out application during the tests.\nFirst, I install the WireMock.Net nuget package in my tests project no projeto de testes.\nUsing Visual Studio Package Manager 1 Install-Package WireMock.Net Or\nUsing .NET CLI 1 dotnet add package WireMock.Net Starting WireMock.Net server To start the WireMock.Net server, I call the Start method of the WireMockServer class, and it returns an object with the server data.\n1 var WireMockSvr = WireMockServer.Start(); Overriding out application configurations With the server started, I override the PokeApiBaseUrl parameter, which holds the Pok√©API URL, in my application configurations using the method WithWebHostBuilder of the WebApplicationFactory:\n1 2 3 4 5 6 var HttpClient = _factory .WithWebHostBuilder(builder =\u0026gt; { builder.UseSetting(\u0026#34;PokeApiBaseUrl\u0026#34;, WireMockSvr.Url); }) .CreateClient(); Mocking the /pokemon endpoint Then, I create the mock for the /pokemon endpoint receiving the parameter value charmander.\nIn the example below, I\u0026rsquo;m using the AutoFixture library to generate an object with random values, that will be returned by the mocked API.\n‚ÑπÔ∏è By using an object, I can compare the return of my application with this object, but it\u0026rsquo;s also possible to configure the return based on an file with a JSON, with the WithBodyFromFile method.\nAlso, I set the headers that will be returned and the HTTP status of the response.\n1 2 3 4 5 6 7 8 9 10 11 12 13 Fixture fixture = new Fixture(); var ResponseObj = fixture.Create\u0026lt;PokemonInfo\u0026gt;(); var ResponseObjJson = JsonSerializer.Serialize(ResponseObj); WireMockSvr .Given(Request.Create() .WithPath(\u0026#34;/pokemon/charmander\u0026#34;) .UsingGet()) .RespondWith(Response.Create() .WithBody(ResponseObjJson) .WithHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) .WithStatusCode(HttpStatusCode.OK)); After that, my application inside the tests will be using the mocked version of the Pok√©API.\nComplete test code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 [Fact] public async Task Get_Existing_Pokemon_Returns_200() { //Arrange var WireMockSvr = WireMockServer.Start(); var HttpClient = _factory .WithWebHostBuilder(builder =\u0026gt; { builder.UseSetting(\u0026#34;PokeApiBaseUrl\u0026#34;, WireMockSvr.Url); }) .CreateClient(); Fixture fixture = new Fixture(); var ResponseObj = fixture.Create\u0026lt;PokemonInfo\u0026gt;(); var ResponseObjJson = JsonSerializer.Serialize(ResponseObj); WireMockSvr .Given(Request.Create() .WithPath(\u0026#34;/pokemon/charmander\u0026#34;) .UsingGet()) .RespondWith(Response.Create() .WithBody(ResponseObjJson) .WithHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) .WithStatusCode(HttpStatusCode.OK)); //Act var HttpResponse = await HttpClient.GetAsync(\u0026#34;/pokemoninfo/charmander\u0026#34;); //Assert HttpResponse.StatusCode.Should().Be(HttpStatusCode.OK); var ResponseJson = await HttpResponse.Content.ReadAsStringAsync(); var PokemonInfo = JsonSerializer.Deserialize\u0026lt;PokemonInfo\u0026gt;(ResponseJson); PokemonInfo.Should().BeEquivalentTo(ResponseObj); WireMockSvr.Stop(); } Example of an unsuccessfull API call scenario Based on the contract of the API, we know that it return the status 404 (Not Found) when the parameter is not a valid Pok√©mon name, so I created a mock that returns this status for the parameter value woodywoodpecker and assert that my application response is correct for this scenario.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 [Fact] public async Task Get_NotExisting_Pokemon_Returns_404() { //Arrange var WireMockSvr = WireMockServer.Start(); var Factory = _factory.WithWebHostBuilder(builder =\u0026gt; { builder.UseSetting(\u0026#34;PokeApiBaseUrl\u0026#34;, WireMockSvr.Url); }); var HttpClient = Factory.CreateClient(); Fixture fixture = new Fixture(); WireMockSvr .Given(Request.Create() .WithPath(\u0026#34;/pokemon/woodywoodpecker\u0026#34;) .UsingGet()) .RespondWith(Response.Create() .WithHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) .WithStatusCode(HttpStatusCode.NotFound)); //Act var HttpResponse = await HttpClient .GetAsync(\u0026#34;/pokemoninfo/woodywoodpecker\u0026#34;); //Assert HttpResponse.StatusCode.Should().Be(HttpStatusCode.NotFound); WireMockSvr.Stop(); } Source code | https://github.com/dgenezini/PokemonInfoAPIWireMockTests\nReferences and links https://martinfowler.com/bliki/IntegrationTest.html https://khorikov.org/posts/2021-11-29-unmanaged-dependencies-explained/ https://github.com/WireMock-Net/WireMock.Net https://github.com/reactiveui/refit https://github.com/AutoFixture/AutoFixture https://github.com/fluentassertions/fluentassertions ","date":"2022-09-25T08:00:00-03:00","image":"https://blog.genezini.com/p/integration-tests-without-api-dependencies-with-asp.net-core-and-wiremock.net/cover.jpg","permalink":"https://blog.genezini.com/p/integration-tests-without-api-dependencies-with-asp.net-core-and-wiremock.net/","title":"Integration tests without API dependencies with ASP.NET Core and WireMock.Net"}]